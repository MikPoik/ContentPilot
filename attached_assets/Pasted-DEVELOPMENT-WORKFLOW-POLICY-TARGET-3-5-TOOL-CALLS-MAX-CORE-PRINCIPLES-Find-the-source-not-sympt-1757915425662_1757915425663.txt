DEVELOPMENT WORKFLOW POLICY - TARGET: 3-5 TOOL CALLS MAX

CORE PRINCIPLES: Find the source not symptom. Fix the pattern not instance. Batch all changes. Trust dev tools. Stop when success confirmed.

MANDATORY 4-PHASE WORKFLOW:

PHASE 1 - PLANNING (0 calls): Map ALL files needed (read + edit targets). Map ALL changes. Read error stack traces completely - deepest frame has real issue. Search error patterns before assuming location.

PHASE 2 - DISCOVERY (1-2 calls): Predict which files to READ AND edit before starting. Batch ALL reads/searches in parallel (3-6 files). NEVER: read→analyze→read. ALWAYS: read(file1)+read(file2)+read(file3)+grep(). Use search_codebase ONLY when truly lost. Be surgical, skip exploration.

PHASE 3 - EXECUTION (1-3 calls): Use multi_edit for ANY file needing multiple changes. NEVER multiple edit() calls to same file. Batch independent changes in parallel. Plan all related changes upfront - don't fix incrementally. Apply patterns consistently across codebase. Fix root causes not symptoms.

PHASE 4 - VALIDATION (0-1 calls): Bundle operations logically. Stop immediately when dev tools confirm success. One restart_workflow only if runtime actually fails.

BATCHING RULES: Maximum 6 tools per batch. Read multiple files simultaneously. Apply edits in parallel when independent. Never serialize what can be batched.

VERIFICATION STOPS: Stop when HMR reloads, console shows expected behavior, LSP errors clear, dev server responds.

SUB-AGENT USAGE: No sub_agent delegation, do the work yourself.

TASK LIST POLICY: No task lists, do a implementation plan ahead and execute.

ARCHITECT POLICY: No architect calls, unless user explicitly asks for.

SUCCESS TARGET: 30-50% cost reduction vs sequential approach. Zero search_codebase when project structure known.

REMEMBER: Always read `replit.md` file for project overview, source structure and full workflow policy.

--- 

Add logging to the chat message flow and duration calculation. When user sends message, vector search, memory saving, user profile updates. So we can see what are bottlenecks in response generation